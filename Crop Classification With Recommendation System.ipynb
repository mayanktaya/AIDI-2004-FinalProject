{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f32dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training and tuning Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Training and tuning XGBoost...\n",
      "Best parameters for XGBoost: {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Evaluating Random Forest...\n",
      "Accuracy for Random Forest: 0.9932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00        26\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      1.00      1.00        17\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       1.00      1.00      1.00        14\n",
      "           8       0.92      1.00      0.96        23\n",
      "           9       1.00      1.00      1.00        20\n",
      "          10       0.92      1.00      0.96        11\n",
      "          11       1.00      1.00      1.00        21\n",
      "          12       1.00      1.00      1.00        19\n",
      "          13       1.00      0.96      0.98        24\n",
      "          14       1.00      1.00      1.00        19\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       1.00      1.00      1.00        14\n",
      "          17       1.00      1.00      1.00        23\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       1.00      1.00      1.00        23\n",
      "          20       1.00      0.89      0.94        19\n",
      "          21       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Evaluating Gradient Boosting...\n",
      "Accuracy for Gradient Boosting: 0.9818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       0.95      1.00      0.98        20\n",
      "           3       1.00      1.00      1.00        26\n",
      "           4       1.00      0.96      0.98        27\n",
      "           5       1.00      1.00      1.00        17\n",
      "           6       0.94      1.00      0.97        17\n",
      "           7       1.00      1.00      1.00        14\n",
      "           8       0.82      1.00      0.90        23\n",
      "           9       1.00      1.00      1.00        20\n",
      "          10       0.92      1.00      0.96        11\n",
      "          11       1.00      0.95      0.98        21\n",
      "          12       1.00      1.00      1.00        19\n",
      "          13       1.00      0.96      0.98        24\n",
      "          14       1.00      1.00      1.00        19\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       1.00      1.00      1.00        14\n",
      "          17       1.00      1.00      1.00        23\n",
      "          18       1.00      0.96      0.98        23\n",
      "          19       1.00      1.00      1.00        23\n",
      "          20       1.00      0.79      0.88        19\n",
      "          21       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.98       440\n",
      "   macro avg       0.98      0.98      0.98       440\n",
      "weighted avg       0.98      0.98      0.98       440\n",
      "\n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Accuracy for XGBoost: 0.9886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       0.95      1.00      0.98        20\n",
      "           3       1.00      1.00      1.00        26\n",
      "           4       1.00      1.00      1.00        27\n",
      "           5       1.00      1.00      1.00        17\n",
      "           6       0.94      1.00      0.97        17\n",
      "           7       1.00      1.00      1.00        14\n",
      "           8       0.96      1.00      0.98        23\n",
      "           9       1.00      1.00      1.00        20\n",
      "          10       0.92      1.00      0.96        11\n",
      "          11       1.00      0.95      0.98        21\n",
      "          12       0.95      1.00      0.97        19\n",
      "          13       1.00      0.96      0.98        24\n",
      "          14       1.00      1.00      1.00        19\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       1.00      1.00      1.00        14\n",
      "          17       1.00      1.00      1.00        23\n",
      "          18       1.00      0.91      0.95        23\n",
      "          19       1.00      1.00      1.00        23\n",
      "          20       1.00      0.95      0.97        19\n",
      "          21       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 18  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for saving models\n",
    "import joblib\n",
    "\n",
    "# Import necessary libraries for preprocessing and training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "crop_data = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "\n",
    "# 1. Separate the features from the target\n",
    "X = crop_data.drop('label', axis=1)\n",
    "y = crop_data['label']\n",
    "\n",
    "# 2. Impute only the numeric features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values in numeric features only\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X[numeric_features] = imputer.fit_transform(X[numeric_features])\n",
    "\n",
    "# Checking for duplicates and removing them\n",
    "X = X.drop_duplicates()\n",
    "\n",
    "# 3. Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save the label encoder\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# 4. Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Feature Scaling using MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "X_train_scaled_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_scaled_minmax = scaler_minmax.transform(X_test)\n",
    "\n",
    "# Apply StandardScaler\n",
    "X_train_scaled_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_scaled_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "# Choosing MinMaxScaler for this example\n",
    "X_train_scaled = X_train_scaled_minmax\n",
    "X_test_scaled = X_test_scaled_minmax\n",
    "\n",
    "# Save the chosen scaler\n",
    "joblib.dump(scaler_minmax, 'scaler_minmax.pkl')  # Save the MinMaxScaler\n",
    "# joblib.dump(scaler_standard, 'scaler_standard.pkl')  # Save the StandardScaler if used\n",
    "\n",
    "# 6. Define and Train Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Choose the grid based on the model\n",
    "grids = {\n",
    "    \"Random Forest\": param_grid_rf,\n",
    "    \"Gradient Boosting\": param_grid_gb,\n",
    "    \"XGBoost\": param_grid_xgb\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training and tuning {name}...\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Save each model as a .pkl file\n",
    "    joblib.dump(best_models[name], f'{name.replace(\" \", \"_\").lower()}_model.pkl')\n",
    "\n",
    "# 7. Evaluate the models\n",
    "evaluation_results = {}\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    evaluation_results[name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": classification_rep,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    }\n",
    "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
    "    print(classification_rep)\n",
    "    print(conf_matrix)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Final output: evaluation_results contains all the metrics for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e93af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
